{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6155d1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.8.0-cp313-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting typing-extensions>=4.10.0 (from torch)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting setuptools (from torch)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Downloading markupsafe-3.0.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Using cached torch-2.8.0-cp313-none-macosx_11_0_arm64.whl (73.6 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Using cached fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading markupsafe-3.0.3-cp313-cp313-macosx_11_0_arm64.whl (12 kB)\n",
      "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Installing collected packages: mpmath, typing-extensions, sympy, setuptools, networkx, MarkupSafe, fsspec, filelock, jinja2, torch\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/10\u001b[0m [torch]m 9/10\u001b[0m [torch]]x]s]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.3 filelock-3.19.1 fsspec-2025.9.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.5 setuptools-80.9.0 sympy-1.14.0 torch-2.8.0 typing-extensions-4.15.0\n"
     ]
    }
   ],
   "source": [
    "! pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51e8841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "# Defining Embedding class\n",
    "\n",
    "class Inputembedding(nn.Module):\n",
    "    # defining constructor\n",
    "\n",
    "    def __init__(self,d_model:int,vocab_size:int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model= d_model # dimension of the word vector\n",
    "        self.vocab_size= vocab_size # total number of word in vocubalory\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.embedding(x) *  math.sqrt(self.d_model)\n",
    "\n",
    " # positional encoding   \n",
    "class positionalEncoding(nn.Module):\n",
    "    def __init__(self,d_model:int,seq_len:int,dropout:float):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model= d_model\n",
    "        self.seq_len= seq_len\n",
    "        self.dropout= nn.Dropout(dropout)\n",
    "        pe= torch.zeros(seq_len,d_model) # create a matrix of shape. (seq_len,d_model)\n",
    "        position= torch.arange(0,seq_len,dtype=torch.float).unsqueeze(1) # position shape will be (seq_len,1) it will show position of each word\n",
    "\n",
    "        div_term= torch.exp(torch.arange(0,d_model,2).float()* (-math.log(10000)/d_model))\n",
    "        # apply the sin to the even position word\n",
    "        pe[:,0::2]= torch.sin(position*div_term)\n",
    "        pe[:,1::2]= torch.cos(position*div_term)\n",
    "        # Batch dimension = number of sentences (or sequences) processed in parallel.\n",
    "        # Positional encoding is shared across all sentences in the batch.\n",
    "        pe= pe.unsqueeze(0) # so it will be dimensioin (1,seq_len,d_model)\n",
    "        self.register_buffer('pe',pe) # add into register buffer \n",
    "\n",
    "    def forward(self,x):\n",
    "        x= x + (self.pe[:,:x.shape[1],:]).requieres_grad(False)\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "# layer Normalization.....\n",
    "\n",
    "class LayerNormalization(nn.Module):\n",
    "    def __init__(self,eps:float=10**-6)->None:\n",
    "        super().__init__()\n",
    "        self.eps= eps\n",
    "        self.alpha= nn.parameter(torch.ones(1))\n",
    "        self.bias= nn.parameter(torch.zeros(0))\n",
    "\n",
    "    def forward(self,x):\n",
    "        mean= x.mean(dim= -1,keepdim=True)\n",
    "        std= x.std(dim= -1,keepdim=True)\n",
    "        return self.alpha*(x-mean)/(std+self.eps) + self.bias\n",
    "\n",
    "\n",
    "# Feed Forword Neural Network class\n",
    "\n",
    "class FNN(nn.Module):\n",
    "    def __init__(self,d_model:int,d_ff:int,dropout:float)->None:\n",
    "        super().__init__()\n",
    "        self.linear_1= nn.Linear(d_model,d_ff)\n",
    "        self.dropout= nn.Dropout(dropout)\n",
    "        self.linear_2= nn.Linear(d_ff,d_model)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # (Batch,seq-len,d_model)----> (Batch,seq-len,d_ff)----> (Batch,seq-len,d_model):\n",
    "\n",
    "        return self.linear_2(self.dropout(torch.relu(self.linear_1(x))))\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732ad5e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
